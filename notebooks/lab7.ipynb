{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Лабораторная работа №7. Рекуррентные нейронные сети для анализа текста\n",
    "Данные: Набор данных для предсказания оценок для отзывов, собранных с сайта imdb.com, который состоит из 50,000 отзывов в виде текстовых файлов. \n",
    "Отзывы разделены на положительные (25,000) и отрицательные (25,000). \n",
    "Данные предварительно токенизированы по принципу “мешка слов”, индексы слов можно взять из словаря (imdb.vocab). \n",
    "Обучающая выборка включает в себя 12,500 положительных и 12,500 отрицательных отзывов, контрольная выборка также содержит 12,500 положительных и 12,500 отрицательных отзывов, а также. \n",
    "Данные можно скачать по ссылке https://ai.stanford.edu/~amaas/data/sentiment/\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Задание 1.\n",
    "Загрузите данные. Преобразуйте текстовые файлы во внутренние структуры данных, которые используют индексы вместо слов.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {
    "pycharm": {
     "is_executing": false,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "from tensorflow import keras\n",
    "import numpy as np\n",
    "from keras.datasets import imdb\n",
    "\n",
    "epochs = 3\n",
    "vocab_size = 10000\n",
    "review_max_len = 200\n",
    "feature_count = 50\n",
    "batch_size = 256\n",
    "\n",
    "data_folder = '../data'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {
    "pycharm": {
     "is_executing": false,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "(X_train, y_train), (X_dev, y_dev) = imdb.load_data(num_words=vocab_size)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "X_train = keras.preprocessing.sequence.pad_sequences(X_train, maxlen=review_max_len)\n",
    "X_dev = keras.preprocessing.sequence.pad_sequences(X_dev, maxlen=review_max_len)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "#### Задание 2.\n",
    "Реализуйте и обучите двунаправленную рекуррентную сеть (LSTM или GRU). Какого качества классификации удалось достичь?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {
    "pycharm": {
     "is_executing": false,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def model_factory():\n",
    "    return keras.models.Sequential([\n",
    "        keras.layers.Embedding(vocab_size, feature_count),\n",
    "        keras.layers.Bidirectional(keras.layers.GRU(units=32)),\n",
    "        keras.layers.Dense(1, activation='sigmoid')\n",
    "    ])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {
    "pycharm": {
     "is_executing": false,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def train(model):\n",
    "    model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "\n",
    "    model.fit(X_train, y_train, validation_data=(X_dev, y_dev), epochs=epochs, \n",
    "              batch_size=batch_size)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {
    "pycharm": {
     "is_executing": false,
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 25000 samples, validate on 25000 samples\n",
      "Epoch 1/3\n",
      "25000/25000 [==============================] - 44s 2ms/sample - loss: 0.5740 - accuracy: 0.6835 - val_loss: 0.3851 - val_accuracy: 0.8334\n",
      "Epoch 2/3\n",
      "25000/25000 [==============================] - 41s 2ms/sample - loss: 0.3020 - accuracy: 0.8782 - val_loss: 0.3530 - val_accuracy: 0.8475\n",
      "Epoch 3/3\n",
      "25000/25000 [==============================] - 42s 2ms/sample - loss: 0.2151 - accuracy: 0.9199 - val_loss: 0.3296 - val_accuracy: 0.8626\n"
     ]
    }
   ],
   "source": [
    "model = model_factory()\n",
    "train(model)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Задание 3.\n",
    "Используйте индексы слов и их различное внутреннее представление (word2vec, glove). Как влияет данное преобразование на качество классификации?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {
    "pycharm": {
     "is_executing": false,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "embeddings_index = dict()\n",
    "with open(data_folder + '/glove6b/glove.6B.50d.txt') as f:\n",
    "    for line in f:\n",
    "        values = line.split()\n",
    "        word = values[0]\n",
    "        coefs = np.asarray(values[1:], dtype='float32')\n",
    "        embeddings_index[word] = coefs\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {
    "pycharm": {
     "is_executing": false,
     "name": "#%%        \n"
    }
   },
   "outputs": [],
   "source": [
    "embedding_matrix = np.zeros((vocab_size, feature_count))\n",
    "for word, i in filter(lambda elem : elem[1] < vocab_size, imdb.get_word_index().items()):\n",
    "    embedding_vector = embeddings_index.get(word)\n",
    "    if embedding_vector is not None:\n",
    "        embedding_matrix[i] = embedding_vector\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {
    "pycharm": {
     "is_executing": false,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def model_factory():\n",
    "    return keras.models.Sequential([\n",
    "        keras.layers.Embedding(vocab_size, feature_count, weights=[embedding_matrix], \n",
    "                               input_length=review_max_len, trainable=False),\n",
    "        keras.layers.Bidirectional(keras.layers.GRU(units=32)),\n",
    "        keras.layers.Dense(1, activation='sigmoid')\n",
    "    ])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 25000 samples, validate on 25000 samples\n",
      "Epoch 1/3\n",
      "25000/25000 [==============================] - 45s 2ms/sample - loss: 0.6927 - accuracy: 0.5249 - val_loss: 0.6879 - val_accuracy: 0.5415\n",
      "Epoch 2/3\n",
      "25000/25000 [==============================] - 65s 3ms/sample - loss: 0.6814 - accuracy: 0.5608 - val_loss: 0.6783 - val_accuracy: 0.5674\n",
      "Epoch 3/3\n",
      "25000/25000 [==============================] - 47s 2ms/sample - loss: 0.6640 - accuracy: 0.5962 - val_loss: 0.6570 - val_accuracy: 0.6102\n"
     ]
    }
   ],
   "source": [
    "model = model_factory()\n",
    "train(model)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Задание 4.\n",
    "Поэкспериментируйте со структурой сети (добавьте больше рекуррентных, полносвязных или сверточных слоев). Как это повлияло на качество классификации?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def model_factory():\n",
    "    return keras.models.Sequential([\n",
    "        keras.layers.Embedding(vocab_size, feature_count, weights=[embedding_matrix], \n",
    "                               input_length=review_max_len),\n",
    "        keras.layers.Bidirectional(keras.layers.GRU(units=32)),\n",
    "        keras.layers.Dense(64, activation='relu'),\n",
    "        keras.layers.Dense(1, activation='sigmoid')\n",
    "    ])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 25000 samples, validate on 25000 samples\n",
      "Epoch 1/3\n",
      "25000/25000 [==============================] - 56s 2ms/sample - loss: 0.6908 - accuracy: 0.5320 - val_loss: 0.6780 - val_accuracy: 0.5682\n",
      "Epoch 2/3\n",
      "25000/25000 [==============================] - 52s 2ms/sample - loss: 0.5856 - accuracy: 0.6790 - val_loss: 0.4389 - val_accuracy: 0.7983\n",
      "Epoch 3/3\n",
      "25000/25000 [==============================] - 46s 2ms/sample - loss: 0.3468 - accuracy: 0.8489 - val_loss: 0.3425 - val_accuracy: 0.8511\n"
     ]
    }
   ],
   "source": [
    "model = model_factory()\n",
    "train(model)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  },
  "pycharm": {
   "stem_cell": {
    "cell_type": "raw",
    "source": [],
    "metadata": {
     "collapsed": false
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}